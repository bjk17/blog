<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Bjarni Jens's blog</title><link href="//blog.bjk.is/" rel="alternate"></link><link href="//blog.bjk.is/feeds/my-nuc-as-a-server.atom.xml" rel="self"></link><id>//blog.bjk.is/</id><updated>2016-05-29T00:00:00+00:00</updated><entry><title>Server version 0.1 -- OS and monitoring</title><link href="//blog.bjk.is/server-version-01-os-and-monitoring.html" rel="alternate"></link><published>2016-05-29T00:00:00+00:00</published><author><name>Bjarni Jens Kristinsson</name></author><id>tag:blog.bjk.is,2016-05-29:server-version-01-os-and-monitoring.html</id><summary type="html">&lt;p&gt;I chose to download and install Ubuntu Desktop 16.04 as there is no difference in the kernel versions and I needed the graphical DE anyway.&lt;/p&gt;
&lt;p&gt;The installation process is really easy and straight-forward. I chose to use the whole mSATA SSD under the OS with default &lt;a href="https://wiki.ubuntu.com/Lvm"&gt;LVM&lt;/a&gt; configuration. I did not choose full disk encryption this time because there are problems with remote reboots (you have to enter the encryption key at startup) but there are &lt;a href="https://benediktkr.github.io/ops/2015/05/01/remote-fde.html"&gt;workarounds&lt;/a&gt; that I might look into later.&lt;/p&gt;
&lt;h3&gt;Configuring the HDD&lt;/h3&gt;
&lt;p&gt;The 2TB HDD was formatted with ext4 from previous installation (when I used the NUC as a desktop PC) and it is packed with various data such as media and backups. I really doubt that ext4 is the best filesystem for this kind of media as I have considerable less space available than on my identical 2TB external hard drive that is formatted with NTFS.&lt;/p&gt;
&lt;p&gt;I mount the HDD under &lt;code&gt;/hdd&lt;/code&gt; and configure it to spin down after 5 minutes of inactivity to save power and reduce background noise. I really don't care about the extra 2-3 seconds of spin-up time for the rare times when I access data on the disk. By running &lt;code&gt;sudo blkid&lt;/code&gt; I found out that the UUID of my partition on the HDD is &lt;code&gt;83652517-02c7-438d-9fad-35469c3a17b8&lt;/code&gt; (it's &lt;a href="https://help.ubuntu.com/community/UsingUUID"&gt;more reliable to use UUIDs&lt;/a&gt; in Linux then &lt;code&gt;/dev/sdXY&lt;/code&gt; addresses as they may change). &lt;/p&gt;
&lt;p&gt;To achieve all this I ran&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;## Find your UUID by running sudo blkid&lt;/span&gt;
&lt;span class="nv"&gt;HDD_UUID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;83652517-02c7-438d-9fad-35469c3a17b8&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;## Mounting the HDD under /hdd and making it permanent&lt;/span&gt;
sudo mkdir /hdd
sudo chown bjarni:bjarni /hdd
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;UUID=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;HDD_UUID&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; /hdd ext4 defaults 0 2&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sudo tee -a /etc/fstab
sudo mount -a

&lt;span class="c1"&gt;## Setting spindown time to 60*5 seconds = 5 minutes&lt;/span&gt;
sudo hdparm -S &lt;span class="m"&gt;60&lt;/span&gt; /dev/disk/by-uuid/&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;HDD_UUID&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;/dev/disk/by-uuid/&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;HDD_UUID&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt; {&lt;/span&gt;
&lt;span class="s2"&gt;    spindown_time = 60&lt;/span&gt;
&lt;span class="s2"&gt;}&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sudo tee -a /etc/hdparm.conf
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Monitoring solution&lt;/h3&gt;
&lt;p&gt;I've been looking into a vast amount of tools to help me monitor and visualize the metrics I mentioned in my &lt;a href="//blog.bjk.is/what-im-aiming-for.html"&gt;last post&lt;/a&gt;. The list includes time series logging and graphing tools such as &lt;a href="https://oss.oetiker.ch/rrdtool/"&gt;RRDtool&lt;/a&gt; with &lt;a href="https://collectd.org/"&gt;collectd&lt;/a&gt; and &lt;a href="http://manpages.ubuntu.com/manpages/xenial/en/man8/sensord.8.html"&gt;sensord&lt;/a&gt; or &lt;a href="http://grafana.org/"&gt;Grafana&lt;/a&gt; with &lt;a href="https://influxdata.com/"&gt;InfluxDB&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, I decided do make some compromises and accept that the server wouldn't be perfect in this first setup so I chose the easy-to-install, configure-free-out-of-the-box-experience &lt;a href="https://my-netdata.io/"&gt;netdata&lt;/a&gt;. There is actually a lot of configable options (the configuration file on my computer is 6656 lines!), but the idea with netdata is that it simply works out-of-the-box. I didn't change a thing and my dashboard looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="My configure-free netdata dashboard" src="//blog.bjk.is/static/netdata_screenshot.png" /&gt;&lt;/p&gt;
&lt;p&gt;Netdata runs in the background and monitors various metrics. Netdata is about &lt;em&gt;"real-time performance monitoring"&lt;/em&gt; and doesn't write anyting to the disk. The default configuration is to keep metrics data for the last hour in memory and discard anything older than that. &lt;/p&gt;
&lt;p&gt;On my NUC netdata uses around 30MiB of RAM and causes ~2% CPU load. Netdata serves its own web server on port 19999 that I open on my laptop on &lt;code&gt;http://localhost:19999&lt;/code&gt; through an SSH tunnel brought up with &lt;code&gt;ssh -L 19999:127.0.0.1:19999 bjk.is&lt;/code&gt; (bjk.is is an entry in my &lt;code&gt;~/.ssh/config&lt;/code&gt; file).&lt;/p&gt;
&lt;p&gt;There is much more data on the dashboard than I usually look at and sometimes I have to scroll very far down to see the numbers that I'm interested in. Even so, there are a few metrics I'd like to have and theoretically I could write add-ons to gather them (which I'll maybe do one day). At least I should edit the configuration file and cut off some metrics to clean up the clutter and lower the load.&lt;/p&gt;
&lt;p&gt;I installed netdata by following the &lt;a href="https://github.com/firehol/netdata/wiki/Installation"&gt;official instructions&lt;/a&gt;. In a nutshell, it goes like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt install zlib1g-dev uuid-dev libmnl-dev gcc make git autoconf autogen automake pkg-config
sudo git clone https://github.com/firehol/netdata.git --depth&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; /usr/src/netdata
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;alias update-netdata=&amp;#39;pushd /usr/src/netdata &amp;amp;&amp;amp; sudo git pull &amp;amp;&amp;amp; sudo ./netdata-installer.sh &amp;amp;&amp;amp; popd&amp;#39;&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; ~/.bash_aliases
&lt;span class="nb"&gt;source&lt;/span&gt; ~/.bash_aliases
update-netdata
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and then I can use the alias &lt;code&gt;update-netdata&lt;/code&gt; when new versions emerge.&lt;/p&gt;</summary><category term="DevOps"></category><category term="infrastructure"></category><category term="Ubuntu"></category><category term="monitoring"></category><category term="netdata"></category></entry><entry><title>What I'm aiming for</title><link href="//blog.bjk.is/what-im-aiming-for.html" rel="alternate"></link><published>2016-05-23T00:00:00+00:00</published><author><name>Bjarni Jens Kristinsson</name></author><id>tag:blog.bjk.is,2016-05-22:what-im-aiming-for.html</id><summary type="html">&lt;p&gt;Before I moved my NUC I had two Raspberry Pis (web server and &lt;a href="https://kodi.tv/"&gt;XBMC/Kodi&lt;/a&gt; media player) and one &lt;a href="http://docs.cubieboard.org/tutorials/cubietruck/start"&gt;Cubietruck&lt;/a&gt; (NFS server) under the TV. The NUC will take over those tasks and provide me with better hardware to test new &lt;em&gt;features&lt;/em&gt;. As I'm living in a small studio apartment with my girlfriend I'll try my best to keep it as silent as its predecessors.&lt;/p&gt;
&lt;h3&gt;A server and HTPC&lt;/h3&gt;
&lt;p&gt;My NUC will not only be a server. I'm taking down the RPi running Kodi and connecting the HDMI cable to the NUC instead. I want to be running a whole DE (Desktop Environment) both for when I turn on the TV and also to have a remote desktop I'd be able to connect to over the internet. Sure, I can do most of the stuff through SSH, but this is one aspect of "poking around with" I'd like to try out.&lt;/p&gt;
&lt;p&gt;I'm going to install Ubuntu 16.04 and I need to chose between installing the server version and applying the &lt;code&gt;ubuntu-desktop&lt;/code&gt; package on top, or installing Ubuntu Desktop and configure server packages afterwards. The semantically correct way would be to install Ubuntu Server and run the DE as a secure and isolated service. I even posted &lt;a href="http://askubuntu.com/questions/765612/running-ubuntu-desktop-in-lxc-lxd-on-top-of-ubuntu-server/"&gt;a question on Askubuntu&lt;/a&gt; wether this was possible using Linux containers (LXC) but haven't gotten any helpful responses yet.&lt;/p&gt;
&lt;h3&gt;Monitoring&lt;/h3&gt;
&lt;p&gt;I'm using this opportunity to build my server &lt;a href="https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design"&gt;bottom-up&lt;/a&gt;. I think that's the right way to build quality software and infrastructure. That means that after I've installed the OS the first thing I should do (after securing SSH) is to set up some kind of monitoring.&lt;/p&gt;
&lt;p&gt;My main points of interest are physical monitoring such as temperature of core components and frequencies of fan and CPU. I want to be well aware of hardware utilization such as SSD/HDD free space and IO, memory usage and network IO. I'm very curious of power usage but it seems I can't read out those stats from the OS unless I buy some kind of (smart) power meter to plug into the wall. When I used a Linux laptop I could read the Watt usage straight from the battery.&lt;/p&gt;
&lt;p&gt;On top of these core metrics there are some extra bits of information I'd like to have displayed on the dashboard. F.ex. how many SSH sessions are currently open, is the HDD in active or standby state, how long since I last rebooted? These are basically metrics that I can produce with simple commands or shell scripts. Later I could add application monitoring for websites and other software I'd be running on the NUC. &lt;/p&gt;
&lt;p&gt;The dashboard would be presented as a website that would be served on an obscure port on the NUC that would not be open to the internet (because this is sensitive information). However, I would be able to view it on my local net as well as remotely by setting up &lt;a href="https://help.ubuntu.com/community/SSH/OpenSSH/PortForwarding"&gt;SSH port forwarding&lt;/a&gt;. &lt;/p&gt;
&lt;h3&gt;Web services&lt;/h3&gt;
&lt;p&gt;I own the domain bjk.is which I will use to connect to the machine and host my main personal website. I will add additional DNS entries beta.bjk.is, bio.bjk.is and now blog.bjk.is for my different subsites (some in collaboration with others). I would like to do that the right way by isolating the websites from the core server and implement them as "detachable components".&lt;/p&gt;
&lt;p&gt;At NextCODE we use &lt;a href="https://aws.amazon.com/"&gt;Amazon Web Services&lt;/a&gt; (AWS) quite a lot. We also manage our own infrastructure with software from &lt;a href="https://www.vmware.com/"&gt;VMware&lt;/a&gt; and &lt;a href="https://www.greenqloud.com/"&gt;Greenqloud&lt;/a&gt;. Both AWS and Greenqloud's &lt;a href="https://www.qstack.com/"&gt;Qstack&lt;/a&gt; have web-based interfaces (as well as scriptable API's) where we can create and start virtual machines (VM) with a public IP address and configurable amount of CPU cores, RAM and storage.&lt;/p&gt;
&lt;p&gt;This sort of &lt;a href="https://en.wikipedia.org/wiki/Cloud_computing#Infrastructure_as_a_service_.28IaaS.29"&gt;infrastructure as a service&lt;/a&gt; (IaaS) is what I aim for when setting up the NUC. There are a lot of limitations, though, as I only have one physical computer and one public IP address to work with. But to some degree I can seperate websites and other processes into pluggable independent containers or VMs that won't affect each other.&lt;/p&gt;
&lt;h3&gt;Network-attached storage (NAS)&lt;/h3&gt;
&lt;p&gt;The underlying server OS have direct access to all the hardware, including the 2TB spinning HDD with all my data (don't worry, I do backups). Therefore, the server OS should also be responsible of exposing and sharing the data with all parties involved. The media player in the DE needs access to it, my other computers on the home network do so too and maybe some future application running on NUC as well. When I'm not at home I want to be able to mount the data drive over the internet. The SSD is dedicated for the OS and other software whether it's core server or running inside containers/VMs.&lt;/p&gt;
&lt;p&gt;In the next blog post(s) I'll write about what feature boxes I managed to tick and how I implemented them.&lt;/p&gt;</summary><category term="DevOps"></category><category term="infrastructure"></category><category term="Ubuntu"></category></entry><entry><title>My hobby project</title><link href="//blog.bjk.is/my-hobby-project.html" rel="alternate"></link><published>2016-05-15T00:00:00+00:00</published><author><name>Bjarni Jens Kristinsson</name></author><id>tag:blog.bjk.is,2016-05-15:my-hobby-project.html</id><summary type="html">&lt;p&gt;So, the main idea behind this blog is to write about what I've done and what I'm about to with this hobby project of mine.&lt;/p&gt;
&lt;p&gt;In a nutshell, I want to learn about Linux, servers, networking, infrastructure and all the best-practises there is to set up and manage my own servers and infrastructure.&lt;/p&gt;
&lt;h3&gt;The inspiration&lt;/h3&gt;
&lt;p&gt;In my undergraduate studies I wrote a &lt;a href="http://skemman.is/handle/1946/22017"&gt;research thesis&lt;/a&gt; on &lt;em&gt;occurrence graphs&lt;/em&gt; under the guidance of &lt;a href="http://ulfarsson.github.io/research.html"&gt;Henning Ulfarsson&lt;/a&gt; from Reykjavik University. Our work could be categorized as &lt;a href="https://en.wikipedia.org/wiki/Experimental_mathematics"&gt;experimental mathematics&lt;/a&gt; because of it's heavy reliance on computer analysis. To get a feeling for our new objects and mathematical structures we often wrote simple programs that looped over millions and billions and even trillions (that's a whopping &lt;span class="math"&gt;\(10^{12}\)&lt;/span&gt;) of permutations to do some simple computations and then aggregate the results over the permutations to a sequence of numbers, something that we have &lt;a href="https://en.wikipedia.org/wiki/Sequence"&gt;a much better understanding of&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What I realized then, and have not stopped thinking about, is how extremely parallell these computations were. Today, all the rage is about &lt;a href="https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units"&gt;programming on the graphics processing units&lt;/a&gt; (GPUs) for parallel tasks. It's all well and good when you have a &lt;a href="https://en.wikipedia.org/wiki/Shared_memory"&gt;shared memory model&lt;/a&gt;, but what if all your parallel tasks can work completely on their own on completely different computers and needed just a simple and short job description? In my and Henning's scenario the job description would only have been a few bytes, given the other computers would have the necessary libraries to do the calculations. I think &lt;a href="http://www.coindesk.com/information/get-started-mining-pools/"&gt;Bitcoin mining pools&lt;/a&gt; works this way.&lt;/p&gt;
&lt;p&gt;My inspiration is to learn enough to be able to &lt;em&gt;expand&lt;/em&gt; my computer and it's computing capabilities to another machine. Eventually I'd be able to &lt;a href="https://en.wikipedia.org/wiki/Scalability#Horizontal_and_vertical_scaling"&gt;scale my computer horizontally&lt;/a&gt; to more computers, over the internet, all over the world.&lt;/p&gt;
&lt;p&gt;I want to poke around to see what's possible and what's not.&lt;/p&gt;
&lt;h3&gt;So I need another computer&lt;/h3&gt;
&lt;p&gt;My first step must therefore be to set up my own server that I can experiment with. And in line with my mathematical background, I want to do it &lt;em&gt;the right way&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I've been tinkering with Linux servers for the last 3-4 years now. I own several Raspberry Pi's and other &lt;a href="https://en.wikipedia.org/wiki/Single-board_computer"&gt;single-board computers&lt;/a&gt; that I've used, among other things, as web servers. I've earned some experience at my work for &lt;a href="https://www.nextcode.com/"&gt;WuXi NextCODE&lt;/a&gt; where I often have to debug Linux server errors.&lt;/p&gt;
&lt;p&gt;But I didn't want to set up another handicapped low-performing Raspberry Pi. Instead I chose to relocate my &lt;a href="http://www.intel.com/content/www/us/en/nuc/nuc-kit-d54250wykh.html"&gt;Intel NUC&lt;/a&gt; with a 15W &lt;a href="http://www.cpubenchmark.net/cpu.php?cpu=Intel+Core+i5-4250U+%40+1.30GHz"&gt;Intel Core i5-4250U&lt;/a&gt; processor, &lt;a href="http://ssd.userbenchmark.com/SpeedTest/12612/Crucial--CT128M550SSD3"&gt;128GB Crucial M550 mSATA&lt;/a&gt; SSD, 2TB spinning HDD (taken from a &lt;a href="http://www.seagate.com/gb/en/products/laptop-mobile-storage/laptop-external-drives/backup-plus/"&gt;Seagate's Backup Plus Portable Drives&lt;/a&gt; unit) and &lt;a href="http://www.pc-specs.com/ram/Crucial/Crucial_BLS2C8G3N169ES4CEU_Arbeitsspeicher_16GB_Kit_(Zwei_8GB_RAMs)_DDR3-RAM/322"&gt;16GB DDR3L 1600MHz memory&lt;/a&gt; from Crucial.&lt;/p&gt;
&lt;p&gt;I put my NUC under the TV and plugged it into the router. In the following blog posts I'll write about how I wanted the server to turn out and what I managed to do in my first attempt.&lt;/p&gt;
&lt;p&gt;&lt;img alt="My NUC and my router" src="//blog.bjk.is/static/IMG_1295.jpg" /&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="DevOps"></category><category term="infrastructure"></category></entry></feed>